{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Unsupervised feature learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem you will see how unsupervised learning can help you train better models even with labeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_x = 32 # width of image\n",
    "image_y = 32 # height of image\n",
    "patch_dim = 8 # height/width of a patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image(object):\n",
    "\n",
    "    def __init__(self,data,label,patches):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        -----------\n",
    "        Takes image related data, called on image creation.\n",
    "        \"\"\"\n",
    "        self.label = label # image label\n",
    "        self.patches = patches.transpose().tolist()\n",
    "        \n",
    "        self.__img_data = data\n",
    "\n",
    "    def view(self):\n",
    "        \"\"\"\n",
    "        Function: View\n",
    "        --------------\n",
    "        Call function to view RGB image\n",
    "        \"\"\"\n",
    "        from PIL import Image\n",
    "        im = Image.fromarray(self.__img_data)\n",
    "        im = im.resize((128,128),Image.BILINEAR)\n",
    "        im.show()\n",
    "\n",
    "    def get_label(self):\n",
    "        \"\"\"\n",
    "        Function: Label\n",
    "        ---------------\n",
    "        Returns label of image\n",
    "        \"\"\"\n",
    "        return self.label\n",
    "\n",
    "    def get_patches(self):\n",
    "        \"\"\"\n",
    "        Function: Patches\n",
    "        -----------------\n",
    "        Returns list of patch vectors. Each patch length patch_size\n",
    "        \"\"\"\n",
    "        return self.patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_helper(name,m):\n",
    "    channels = 3\n",
    "    patch_dim = 8\n",
    "    patches_per_image = (image_x/patch_dim)*(image_y/patch_dim)\n",
    "\n",
    "    images = np.fromfile('data/images_'+name+'.bin',dtype=np.uint8)\n",
    "    images = images.reshape((m,image_x,image_y,channels))\n",
    "\n",
    "    patches = np.fromfile('data/patches_'+name+'.bin',dtype=np.float32)\n",
    "    patches = patches.reshape((patch_dim**2,-1))\n",
    "\n",
    "    labels = np.fromfile('data/labels_'+name+'.bin',dtype=np.uint8)\n",
    "\n",
    "    image_list = []\n",
    "    for i in range(images.shape[0]):\n",
    "        image_list.append(Image(images[i,...],labels[i],\n",
    "          patches[:,int(i*patches_per_image):int((i+1)*patches_per_image)]))\n",
    "    \n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_helper(patches,num):\n",
    "    from PIL import Image\n",
    "    \n",
    "    xnum = int(np.sqrt(num))\n",
    "    if xnum**2 == num:\n",
    "        ynum = xnum\n",
    "    else:\n",
    "        ynum = xnum+1\n",
    "\n",
    "    imDim = 50\n",
    "\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        patches = patches-np.min(patches)\n",
    "        patches = patches/np.max(patches)\n",
    "        patchDim = patches.shape[0]\n",
    "        image = np.zeros(((patchDim+1)*ynum+1,(patchDim+1)*xnum+1))\n",
    "        for i in range(ynum):\n",
    "            for j in range(xnum):\n",
    "                imnum = i*xnum+j\n",
    "                if imnum>=num:\n",
    "                    break\n",
    "                ax = plt.subplot2grid((ynum,xnum),(i,j))\n",
    "                ax.imshow(patches[:,:,i*xnum+j].squeeze(), cmap = plt.get_cmap('gray'))\n",
    "                ax.axes.get_xaxis().set_visible(False)\n",
    "                ax.axes.get_yaxis().set_visible(False)\n",
    "                \n",
    "        plt.subplots_adjust(wspace=-.5 ,hspace=0.2)\n",
    "        plt.show()\n",
    "        return\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    # rescale to be [0-255]\n",
    "    patches = patches-np.min(patches)\n",
    "    patches = 255*patches/np.max(patches)\n",
    "\n",
    "    newpatches = np.empty((imDim,imDim,num))\n",
    "\n",
    "    for p in range(num):\n",
    "        patch = patches[:,:,p].squeeze().copy()\n",
    "        im = Image.fromarray(patch)\n",
    "        im = im.resize((imDim,imDim),Image.BILINEAR)\n",
    "        newpatches[:,:,p] = np.asarray(im.convert('L'))\n",
    "\n",
    "    patches = newpatches\n",
    "    image = np.zeros(((imDim+1)*ynum+1,(imDim+1)*xnum+1))\n",
    "\n",
    "    for i in range(ynum):\n",
    "        for j in range(xnum):\n",
    "            imnum = i*xnum+j\n",
    "            if imnum>=num:\n",
    "                break\n",
    "            image[i*(imDim+1)+1:i*(imDim+1)+imDim+1, \\\n",
    "                  j*(imDim+1)+1:j*(imDim+1)+imDim+1] \\\n",
    "                  = patches[:,:,imnum]\n",
    "    image = Image.fromarray(image, 'L')\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_features(images):\n",
    "    \"\"\"\n",
    "    Extracts raw pixel features for all images.  Returns a 2-D array\n",
    "    of size featDim x numExamples and a vector of labels.\n",
    "    \"\"\"\n",
    "    X = [np.array(image.get_patches()).ravel() for image in images]\n",
    "    X = np.vstack(X).transpose() # featdim by num samples\n",
    "    # label array\n",
    "    Y = np.array([image.get_label() for image in images])\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_patches(patches):\n",
    "    \"\"\"\n",
    "    Function: View Patches\n",
    "    ----------------------\n",
    "    Pass in an array of patches (or centroids) in order to view them as\n",
    "    images.\n",
    "    \"\"\"\n",
    "    view_helper(patches.reshape(patch_dim,patch_dim,-1),patches.shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_images = 2000\n",
    "file_tag = 'train'\n",
    "train_image_list = load_helper(file_tag,num_train_images)\n",
    "\n",
    "num_test_images = 1000\n",
    "file_tag = 'test'\n",
    "test_image_list = load_helper(file_tag,num_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,train_Y = pixel_features(train_image_list)\n",
    "test_X,test_Y = pixel_features(test_image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024, 2000), (2000,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.77245879e+00 -2.36186966e-01  4.86198068e-02 ... -2.42185146e-01\n",
      "  -1.57253239e-02  9.44859445e-01]\n",
      " [-2.66454482e+00 -1.67018801e-01  1.09784670e-01 ... -1.25524580e-01\n",
      "  -4.30927604e-01  1.60894477e+00]\n",
      " [ 1.04330039e+00 -5.38556993e-01  1.20907120e-01 ... -3.12024087e-01\n",
      "   2.23523572e-01  3.41507196e-01]\n",
      " ...\n",
      " [ 1.45803440e+00  3.45114350e-01  2.76380658e-01 ... -7.04077601e-01\n",
      "   9.04016048e-02  1.22188699e+00]\n",
      " [ 2.40676475e+00 -1.25334633e-03 -8.77847150e-02 ... -2.81709522e-01\n",
      "  -4.84565198e-01  1.68098342e+00]\n",
      " [ 2.08898202e-01 -3.34747881e-02  5.40620685e-02 ... -1.38029903e-01\n",
      "   3.84905010e-01  1.27014351e+00]]\n",
      "\n",
      "[1 1 1 1 0 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(train_X[:10])\n",
    "print(\"\")\n",
    "print(train_Y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train logistic regression on the raw pixel data and report the train and test set results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "lr = LogisticRegression().fit(train_X.T, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set results:  0.961\n",
      "Test set results:   0.534\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set results: \", lr.score(train_X.T, train_Y))\n",
    "print(\"Test set results:  \", lr.score(test_X.T, test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train SVM on the raw pixel data and report the train and test set results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC().fit(train_X.T, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set results:  0.9585\n",
      "Test set results:  0.623\n"
     ]
    }
   ],
   "source": [
    "train_pred = svc.predict(train_X.T)\n",
    "test_pred = svc.predict(test_X.T)\n",
    "\n",
    "print(\"Train set results: \", accuracy_score(train_pred, train_Y))\n",
    "print(\"Test set results: \", accuracy_score(test_pred, test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train XGBoost on the raw pixel data and report the train and test set results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set results:  0.974\n",
      "Test set results:  0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schwajka\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\schwajka\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier = xgb.XGBClassifier()\n",
    "xgb_classifier.fit(train_X.T, train_Y)\n",
    "\n",
    "print(\"Train set results: \", xgb_classifier.score(train_X.T, train_Y))\n",
    "print(\"Test set results: \", xgb_classifier.score(test_X.T, test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning better features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of hand-designing better features let us see if we can learn them directly from data. Each image is a 32x32 grid of pixels. We will divide the image into sixteen 8x8 \"patches\". Next, we will use K-means to cluster all the patches into centroids. These centroids will then allow us to use a better feature representation of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see how we can get patches from the images and visualize them. Make sure you understand the dimensions of every array and what they mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 2\n",
    "patches = np.hstack([np.array(image.get_patches()).transpose() for image in train_image_list[:num_images]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_patches(patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run k-means from scikit-learn to group all patches into clusters. Initially, pick the number of clusters according to your best guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 16000)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_images = 1000\n",
    "patches = np.hstack([np.array(image.get_patches()).transpose() for image in train_image_list[:num_images]])\n",
    "patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=22).fit(patches.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, visualize the centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "centroids = np.array([kmeans.cluster_centers_.T]) # Please use this variable name for the array of centroids\n",
    "view_patches(centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing examples in a new way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you have the centroids defining similar groups in your patches. Represent every image in your training and test set in distances between the patch and each centroid. For example, if you used 10 clusters and each image has 16 patches, new representation of the image will be a vector of 160 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(352, 2000)\n",
      "(352, 1000)\n"
     ]
    }
   ],
   "source": [
    "train_X_new = np.array([kmeans.transform(item).flatten() for item in [np.array(item.get_patches()) for item in train_image_list]]).T\n",
    "test_X_new = np.array([kmeans.transform(item).flatten() for item in [np.array(item.get_patches()) for item in test_image_list]]).T\n",
    "print(train_X_new.shape)\n",
    "print(test_X_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train all three classifiers from the above (logistic regression, SVM and XGBoost) on the new image representation. Report the train and test set results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New train set results:  0.7735\n",
      "New test set results:   0.647\n"
     ]
    }
   ],
   "source": [
    "lr_new = LogisticRegression().fit(train_X_new.T, train_Y)\n",
    "\n",
    "print(\"New train set results: \", lr_new.score(train_X_new.T, train_Y))\n",
    "print(\"New test set results:  \", lr_new.score(test_X_new.T, test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New train set results:  0.9925\n",
      "New test set results:  0.614\n"
     ]
    }
   ],
   "source": [
    "svc_new = SVC().fit(train_X_new.T, train_Y)\n",
    "\n",
    "train_pred = svc_new.predict(train_X_new.T)\n",
    "test_pred = svc_new.predict(test_X_new.T)\n",
    "\n",
    "print(\"New train set results: \", accuracy_score(train_pred, train_Y))\n",
    "print(\"New test set results: \", accuracy_score(test_pred, test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New train set results:  0.8825\n",
      "New test set results:  0.666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schwajka\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\schwajka\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier_new = xgb.XGBClassifier()\n",
    "xgb_classifier_new.fit(train_X_new.T, train_Y)\n",
    "\n",
    "print(\"New train set results: \", xgb_classifier_new.score(train_X_new.T, train_Y))\n",
    "print(\"New test set results: \", xgb_classifier_new.score(test_X_new.T, test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the best out of it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In industry, we typically try to get as much as possible out of the data we have. Try different number of clusters and different configuration of the models and report the best accuracy you got on the test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
